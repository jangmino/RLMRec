{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate async request JSON file for ChatComplete API: User Profile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "with open(\"../specs/.openai_api_key\", \"r\") as f:\n",
    "    ss = f.readline().strip()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "model_list = client.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(id='dall-e-3', created=1698785189, object='model', owned_by='system')\n",
      "Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system')\n",
      "Model(id='dall-e-2', created=1698798177, object='model', owned_by='system')\n",
      "Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal')\n",
      "Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system')\n",
      "Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system')\n",
      "Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system')\n",
      "Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system')\n",
      "Model(id='babbage-002', created=1692634615, object='model', owned_by='system')\n",
      "Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system')\n",
      "Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-mini', created=1721172741, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-mini-2024-07-18', created=1721172717, object='model', owned_by='system')\n",
      "Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-2024-08-06', created=1722814719, object='model', owned_by='system')\n",
      "Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai')\n",
      "Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal')\n",
      "Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal')\n",
      "Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal')\n",
      "Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system')\n",
      "Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system')\n",
      "Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system')\n",
      "Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system')\n",
      "Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system')\n",
      "Model(id='gpt-4o', created=1715367049, object='model', owned_by='system')\n",
      "Model(id='davinci-002', created=1692634301, object='model', owned_by='system')\n",
      "Model(id='gpt-4', created=1687882411, object='model', owned_by='openai')\n",
      "Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai')\n",
      "Model(id='gpt-4o-2024-05-13', created=1715368132, object='model', owned_by='system')\n",
      "Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system')\n",
      "Model(id='ft:gpt-4o-mini-2024-07-18:sungshin-women-s-university:recipe-ner:9oliRjuP:ckpt-step-101', created=1721886847, object='model', owned_by='sungshin-women-s-university-1')\n",
      "Model(id='ft:gpt-4o-mini-2024-07-18:sungshin-women-s-university:recipe-ner:9oliRUul:ckpt-step-202', created=1721886847, object='model', owned_by='sungshin-women-s-university-1')\n",
      "Model(id='ft:gpt-4o-mini-2024-07-18:sungshin-women-s-university:recipe-ner:9oliRolo', created=1721886848, object='model', owned_by='sungshin-women-s-university-1')\n"
     ]
    }
   ],
   "source": [
    "for x in model_list: print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine_id='gpt-3.5-turbo-16k'\n",
    "engine_id='gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_json_body(request_id, system_prompt, user_prompt):\n",
    "    dic = { \n",
    "        'model':engine_id,\n",
    "        'messages':[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        'temperature':0.0,\n",
    "        'metadata':{'request_id':request_id},\n",
    "    }\n",
    "    return json.dumps(dic, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The prompt temmplate for generating User Profile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You will serve as an assistant to help me determine which types of products a specific user is likely to buy.\n",
    "I will provide you with information about products that the user has purchased, as well as his or her reviews of those products.\n",
    "Here are the instructions:\n",
    "1. Each purchased product will be described in JSON format, with the following attributes:\n",
    "{\n",
    "    \"title\": \"the title of the product in Korean\", (if there is no title, I will set this value to \"None\")\n",
    "    \"description\": \"a description of what types of users will like this product in Korean\",(if there is no description, I will set this value to \"None\"),\n",
    "    \"review\": \"the user's review on the product\" (if there is no review, I will set this value to \"None\")\n",
    "}\n",
    "\n",
    "2. The information I will give you:\n",
    "PURCHASED PRODUCTS: a list of JSON strings describing the items that the user has purchased.\n",
    "\n",
    "Requirements:\n",
    "1. Please provide your decision in JSON format, following this structure:\n",
    "{\n",
    "    \"summarization\": \"A summarization of what types of products this user is likely to enjoy\" (if you are unable to summarize it, please set this value to \"None\")\n",
    "    \"reasoning\": \"briefly explain your reasoning for the summarization\"\n",
    "}\n",
    "2. Please ensure that the \"summarization\" is no longer than 200 words.\n",
    "3. The \"reasoning\" has no word limits.\n",
    "4. Do not provided any other text outside the JSON string.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compact_history_df = pd.read_pickle('/Jupyter/dev_src/RLMRec/data/katchers/intermediate/compact_history_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_request_file_path = '/Jupyter/dev_src/RLMRec/data/katchers/intermediate/openai-request-users.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(api_request_file_path, 'w') as f:\n",
    "    cnt = 0\n",
    "    \n",
    "    for _, row in compact_history_df.iterrows():\n",
    "        jsonl = make_json_body(\n",
    "            request_id=f\"{row.name}\",#cnt+i,\n",
    "            system_prompt=system_prompt,\n",
    "            user_prompt=row['user_profile_input']\n",
    "            )      \n",
    "        f.write(jsonl + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis generated responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_file_path = '/Jupyter/dev_src/RLMRec/data/katchers/intermediate/openai-response-users.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_fname =  response_file_path\n",
    "datas = []\n",
    "request_ids = []\n",
    "# results = {}\n",
    "with open(in_fname, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        data = json.loads(line)\n",
    "        if isinstance(data[1] , dict):\n",
    "            # results[i] = data\n",
    "            datas.append(data[1]['choices'][0]['message']['content'])\n",
    "            request_ids.append(data[2]['request_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'request_id': request_ids, 'response': datas})\n",
    "df['response'] = df['response'].str.strip()\n",
    "df['uid'] = df.request_id.astype(int)\n",
    "profile_df = df.sort_values(by='uid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate aynsc request JSON file for Embedding API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_id</th>\n",
       "      <th>response</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13450</th>\n",
       "      <td>0</td>\n",
       "      <td>{\\n    \"summarization\": \"이 사용자는 주방용품, 개인 위생 제품...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10084</th>\n",
       "      <td>1</td>\n",
       "      <td>{\\n    \"summarization\": \"이 사용자는 신선한 농산물과 가공육 제...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2</td>\n",
       "      <td>{\\n    \"summarization\": \"이 사용자는 신선한 채소와 반찬을 선호...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13451</th>\n",
       "      <td>3</td>\n",
       "      <td>{\\n    \"summarization\": \"이 사용자는 간편하고 건강한 식품, 특...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>{\\n    \"summarization\": \"이 사용자는 청소 및 세탁 관련 제품과...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16808</th>\n",
       "      <td>16808</td>\n",
       "      <td>{\\n    \"summarization\": \"이 사용자는 주름 개선 및 피부 관리 ...</td>\n",
       "      <td>16808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16807</th>\n",
       "      <td>16809</td>\n",
       "      <td>{\\n    \"summarization\": \"이 사용자는 주름 개선 및 피부 관리 ...</td>\n",
       "      <td>16809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13445</th>\n",
       "      <td>16810</td>\n",
       "      <td>{\\n    \"summarization\": \"이 사용자는 주름 개선과 피부 관리에 ...</td>\n",
       "      <td>16810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16810</th>\n",
       "      <td>16811</td>\n",
       "      <td>{\\n    \"summarization\": \"이 사용자는 주름 개선 및 피부 관리 ...</td>\n",
       "      <td>16811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10086</th>\n",
       "      <td>16812</td>\n",
       "      <td>{\\n    \"summarization\": \"이 사용자는 피부 진정과 보습에 효과적...</td>\n",
       "      <td>16812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16813 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      request_id                                           response    uid\n",
       "13450          0  {\\n    \"summarization\": \"이 사용자는 주방용품, 개인 위생 제품...      0\n",
       "10084          1  {\\n    \"summarization\": \"이 사용자는 신선한 농산물과 가공육 제...      1\n",
       "55             2  {\\n    \"summarization\": \"이 사용자는 신선한 채소와 반찬을 선호...      2\n",
       "13451          3  {\\n    \"summarization\": \"이 사용자는 간편하고 건강한 식품, 특...      3\n",
       "16             4  {\\n    \"summarization\": \"이 사용자는 청소 및 세탁 관련 제품과...      4\n",
       "...          ...                                                ...    ...\n",
       "16808      16808  {\\n    \"summarization\": \"이 사용자는 주름 개선 및 피부 관리 ...  16808\n",
       "16807      16809  {\\n    \"summarization\": \"이 사용자는 주름 개선 및 피부 관리 ...  16809\n",
       "13445      16810  {\\n    \"summarization\": \"이 사용자는 주름 개선과 피부 관리에 ...  16810\n",
       "16810      16811  {\\n    \"summarization\": \"이 사용자는 주름 개선 및 피부 관리 ...  16811\n",
       "10086      16812  {\\n    \"summarization\": \"이 사용자는 피부 진정과 보습에 효과적...  16812\n",
       "\n",
       "[16813 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_id='text-embedding-3-small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_json_body(engine_id, idx, body):\n",
    "    dic = { \n",
    "        'model':engine_id,\n",
    "        'input':body,\n",
    "        'metadata': {\"request_id\": idx}\n",
    "    }\n",
    "    return json.dumps(dic, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_request_file_path = '/Jupyter/dev_src/RLMRec/data/katchers/intermediate/openai-request-users-embed.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(api_request_file_path, 'w') as f:\n",
    "    cnt = 0\n",
    "    \n",
    "    for _, row in profile_df.iterrows():\n",
    "        jsonl = make_json_body(\n",
    "            engine_id=engine_id,\n",
    "            idx = row['uid'],\n",
    "            body=row['response']\n",
    "            )      \n",
    "        f.write(jsonl + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis generated responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data_path = '/Jupyter/dev_src/RLMRec/data/katchers/intermediate/openai-response-users-embed.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_fname = generated_data_path\n",
    "datas = []\n",
    "dic = OrderedDict()\n",
    "with open(in_fname, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        data = json.loads(line)\n",
    "        \n",
    "        IDX = data[2]['request_id']\n",
    "        embedding = data[1]['data'][0]['embedding']\n",
    "        \n",
    "        dic[IDX] = embedding\n",
    "result_df = pd.DataFrame.from_records([{'IDX':k, 'embedding':v} for k, v in dic.items()]).sort_values('IDX')\n",
    "result_df.set_index('IDX', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write User Embedding file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.vstack(result_df['embedding'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Jupyter/dev_src/RLMRec/data/katchers/usr_emb_np.pkl', 'wb') as file:\n",
    "    pickle.dump(embedding_matrix, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16813, 1536)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
