{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate async request JSON file for ChatComplete API: Item Profile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "with open(\"../specs/.openai_api_key\", \"r\") as f:\n",
    "    ss = f.readline().strip()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "model_list = client.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(id='dall-e-3', created=1698785189, object='model', owned_by='system')\n",
      "Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system')\n",
      "Model(id='dall-e-2', created=1698798177, object='model', owned_by='system')\n",
      "Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal')\n",
      "Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system')\n",
      "Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system')\n",
      "Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system')\n",
      "Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system')\n",
      "Model(id='babbage-002', created=1692634615, object='model', owned_by='system')\n",
      "Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system')\n",
      "Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-mini', created=1721172741, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-mini-2024-07-18', created=1721172717, object='model', owned_by='system')\n",
      "Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-2024-08-06', created=1722814719, object='model', owned_by='system')\n",
      "Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai')\n",
      "Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal')\n",
      "Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal')\n",
      "Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal')\n",
      "Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system')\n",
      "Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system')\n",
      "Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system')\n",
      "Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system')\n",
      "Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system')\n",
      "Model(id='gpt-4o', created=1715367049, object='model', owned_by='system')\n",
      "Model(id='davinci-002', created=1692634301, object='model', owned_by='system')\n",
      "Model(id='gpt-4', created=1687882411, object='model', owned_by='openai')\n",
      "Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai')\n",
      "Model(id='gpt-4o-2024-05-13', created=1715368132, object='model', owned_by='system')\n",
      "Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system')\n",
      "Model(id='ft:gpt-4o-mini-2024-07-18:sungshin-women-s-university:recipe-ner:9oliRjuP:ckpt-step-101', created=1721886847, object='model', owned_by='sungshin-women-s-university-1')\n",
      "Model(id='ft:gpt-4o-mini-2024-07-18:sungshin-women-s-university:recipe-ner:9oliRUul:ckpt-step-202', created=1721886847, object='model', owned_by='sungshin-women-s-university-1')\n",
      "Model(id='ft:gpt-4o-mini-2024-07-18:sungshin-women-s-university:recipe-ner:9oliRolo', created=1721886848, object='model', owned_by='sungshin-women-s-university-1')\n"
     ]
    }
   ],
   "source": [
    "for x in model_list: print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine_id='gpt-3.5-turbo-16k'\n",
    "engine_id='gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_json_body(request_id, system_prompt, user_prompt):\n",
    "    dic = { \n",
    "        'model':engine_id,\n",
    "        'messages':[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        'temperature':0.0,\n",
    "        'metadata':{'request_id':request_id},\n",
    "    }\n",
    "    return json.dumps(dic, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The prompt temmplate for generating Item Profile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You will serve as an assistant to help me summarize which types of users would enjoy a specific product.\n",
    "I will provide you with the title and a description of the product.\n",
    "Here are the instructions:\n",
    "1. I will provide you with information in the form of a JSON string that describes the product:\n",
    "{\n",
    "    \"title\": \"the title of the product in Korean\", (if there is no title, I will set this value to \"None\")\n",
    "    \"description\": \"a description of the product in Korean\", (if there is no description, I will set this value to \"None\")\n",
    "}\n",
    "\n",
    "Requirements:\n",
    "1. Please provide your answer in JSON format, following this structure:\n",
    "{\n",
    "    \"summarization\": \"A summarization of what types of users would enjoy this product in Korean\" (if you are unable to summarize it, please set this value to \"None\")\n",
    "    \"reasoning\": \"briefly explain your reasoning for the summarization in Korean\"\n",
    "}\n",
    "2. Please ensure that the \"summarization\" is no longer than 200 words.\n",
    "3. Please ensure that the \"reasoning\" is no longer than 200 words.\n",
    "4. Do not provide any other text outside the JSON string.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df = pd.read_pickle('/Jupyter/dev_src/RLMRec/data/katchers/intermediate/item_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_request_file_path = '/Jupyter/dev_src/RLMRec/data/katchers/intermediate/openai-request-items.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(api_request_file_path, 'w') as f:\n",
    "    cnt = 0\n",
    "    \n",
    "    for _, row in item_df.iterrows():\n",
    "        jsonl = make_json_body(\n",
    "            request_id=f\"{row.name}\",\n",
    "            system_prompt=system_prompt,\n",
    "            user_prompt=str({\"title\":row['title'], \"description\":\"None\"})\n",
    "            )      \n",
    "        f.write(jsonl + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis generated responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_file_path = '/Jupyter/dev_src/RLMRec/data/katchers/intermediate/openai-response-items.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_fname =  response_file_path\n",
    "datas = []\n",
    "request_ids = []\n",
    "# results = {}\n",
    "with open(in_fname, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        data = json.loads(line)\n",
    "        if isinstance(data[1] , dict):\n",
    "            # results[i] = data\n",
    "            datas.append(data[1]['choices'][0]['message']['content'])\n",
    "            request_ids.append(data[2]['request_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'request_id': request_ids, 'response': datas})\n",
    "df['response'] = df['response'].str.strip()\n",
    "df['iid'] = df.request_id.astype(int)\n",
    "profile_df = df.sort_values(by='iid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate aynsc request JSON file for Embedding API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_id</th>\n",
       "      <th>response</th>\n",
       "      <th>iid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>{\\n    \"summarization\": \"이 제품은 피부 관리에 관심이 많은 사...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{\\n    \"summarization\": \"욕실 청소를 자주 하는 사용자, 청소 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>{\\n    \"summarization\": \"이 제품은 주방에서 음식을 보관하고자 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>3</td>\n",
       "      <td>{\\n    \"summarization\": \"음식 안전과 청결을 중시하는 가정주부 ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4</td>\n",
       "      <td>{\\n    \"summarization\": \"일반일회용장갑을 필요로 하는 사용자, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>1664</td>\n",
       "      <td>{\\n    \"summarization\": \"피부 진정과 보습을 원하는 사용자들이 ...</td>\n",
       "      <td>1664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>1665</td>\n",
       "      <td>{\\n    \"summarization\": \"이 제품은 다이어트와 건강에 관심이 있...</td>\n",
       "      <td>1665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>1666</td>\n",
       "      <td>{\\n    \"summarization\": \"주름 개선과 피부 관리를 원하는 사용자...</td>\n",
       "      <td>1666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>1667</td>\n",
       "      <td>{\\n    \"summarization\": \"안티에이징 효과를 원하는 사용자, 특히...</td>\n",
       "      <td>1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>1668</td>\n",
       "      <td>{\\n    \"summarization\": \"이 제품은 피부 미백과 보습에 관심이 ...</td>\n",
       "      <td>1668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1669 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     request_id                                           response   iid\n",
       "33            0  {\\n    \"summarization\": \"이 제품은 피부 관리에 관심이 많은 사...     0\n",
       "0             1  {\\n    \"summarization\": \"욕실 청소를 자주 하는 사용자, 청소 ...     1\n",
       "35            2  {\\n    \"summarization\": \"이 제품은 주방에서 음식을 보관하고자 ...     2\n",
       "81            3  {\\n    \"summarization\": \"음식 안전과 청결을 중시하는 가정주부 ...     3\n",
       "51            4  {\\n    \"summarization\": \"일반일회용장갑을 필요로 하는 사용자, ...     4\n",
       "...         ...                                                ...   ...\n",
       "1663       1664  {\\n    \"summarization\": \"피부 진정과 보습을 원하는 사용자들이 ...  1664\n",
       "1667       1665  {\\n    \"summarization\": \"이 제품은 다이어트와 건강에 관심이 있...  1665\n",
       "1665       1666  {\\n    \"summarization\": \"주름 개선과 피부 관리를 원하는 사용자...  1666\n",
       "1664       1667  {\\n    \"summarization\": \"안티에이징 효과를 원하는 사용자, 특히...  1667\n",
       "1666       1668  {\\n    \"summarization\": \"이 제품은 피부 미백과 보습에 관심이 ...  1668\n",
       "\n",
       "[1669 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_id='text-embedding-3-small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_json_body(engine_id, idx, body):\n",
    "    dic = { \n",
    "        'model':engine_id,\n",
    "        'input':body,\n",
    "        'metadata': {\"request_id\": idx}\n",
    "    }\n",
    "    return json.dumps(dic, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_request_file_path = '/Jupyter/dev_src/RLMRec/data/katchers/intermediate/openai-request-items-embed.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(api_request_file_path, 'w') as f:\n",
    "    cnt = 0\n",
    "    \n",
    "    for _, row in profile_df.iterrows():\n",
    "        jsonl = make_json_body(\n",
    "            engine_id=engine_id,\n",
    "            idx = row['iid'],\n",
    "            body=row['response']\n",
    "            )      \n",
    "        f.write(jsonl + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis generated responses\n",
    "\n",
    "(1533, 1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data_path = '/Jupyter/dev_src/RLMRec/data/katchers/intermediate/openai-response-items-embed.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_fname = generated_data_path\n",
    "datas = []\n",
    "dic = OrderedDict()\n",
    "with open(in_fname, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        data = json.loads(line)\n",
    "        \n",
    "        IDX = data[2]['request_id']\n",
    "        embedding = data[1]['data'][0]['embedding']\n",
    "        \n",
    "        dic[IDX] = embedding\n",
    "result_df = pd.DataFrame.from_records([{'IDX':k, 'embedding':v} for k, v in dic.items()]).sort_values('IDX')\n",
    "result_df.set_index('IDX', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Item Embedding file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.vstack(result_df['embedding'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Jupyter/dev_src/RLMRec/data/katchers/itm_emb_np.pkl', 'wb') as file:\n",
    "    pickle.dump(embedding_matrix, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1669, 1536)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
